{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the docs\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./files/about_nutrition.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amishchopra/.local/share/virtualenvs/trying_llms-tq-8R2qj/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/amishchopra/.local/share/virtualenvs/trying_llms-tq-8R2qj/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/amishchopra/.local/share/virtualenvs/trying_llms-tq-8R2qj/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# use chromadb for embedding \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# split the document into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# define the embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# store chunks as embedding to vectorstore ie chromadb\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is hydration important?\n",
      "\n",
      "According to the provided context, water plays a vital role in digestion, nutrient absorption, waste removal, temperature regulation, and lubrication of joints. Dehydration, even mild, can lead to fatigue, headaches, and decreased cognitive function. Therefore, it is essential for maintaining a well-hydrated and healthy body, with a recommended daily goal of eight glasses of water."
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# take query from user and do a similarity seach in chromadb which will be our context\n",
    "query = \"Why is hydration important?\"\n",
    "context_from_docs = db.similarity_search(query)\n",
    "\n",
    "# create context query prompt\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {user_question}\n",
    "\n",
    "        Instructions:\n",
    "\n",
    "        Answer the user's question \"{user_question}\" using the information provided in the context \"{context}\".\n",
    "        Ensure your answer is factually grounded in the context.\n",
    "        If the context doesn't have enough information to answer the question, return \"I don't have that knowledge\".\n",
    "        Optional:\n",
    "\n",
    "        You can add additional information to the Instructions section depending on your specific needs.\n",
    "        For example, you might specify the desired answer length or tone.\n",
    "        Consider including a repetition of the instructions at the end for better model adherence.\n",
    "        Example:\n",
    "\n",
    "        Context:  The capital of France is Paris. Paris is a beautiful city with a rich history. It is famous for its landmarks like the Eiffel Tower and the Louvre Museum.\n",
    "\n",
    "        Question: What is the capital of France?\n",
    "\n",
    "        Instructions: Answer the user's question \"What is the capital of France?\" using the information provided in the context \"The capital of France is Paris...\". Ensure your answer is factually grounded in the context. If the context doesn't have enough information to answer the question, return \"I don't have that knowledge\".\n",
    "\n",
    "        Answer: Paris\n",
    "\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "# chain.invoke({\"context\":context_from_docs, \"user_question\" : query})\n",
    "\n",
    "# steaming the output \n",
    "async for chunk in chain.astream({\"context\":context_from_docs, \"user_question\" : query}):\n",
    "    print(chunk, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
